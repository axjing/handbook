{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\Coding\\\\handbook\\\\notebook', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\python311.zip', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\DLLs', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl', '', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\Pythonwin', '/home/test']\n",
      "['d:\\\\Coding\\\\handbook\\\\notebook', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\python311.zip', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\DLLs', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl', '', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\axjing\\\\miniconda3\\\\envs\\\\dl\\\\Lib\\\\site-packages\\\\Pythonwin', '/home/test', '/home/test']\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# 环境变量\n",
    "env_v=sys.path\n",
    "print(env_v)\n",
    "# 添加环境变量\n",
    "path='/home/test'\n",
    "add_env_v=sys.path.append(path)\n",
    "print(sys.path)\n",
    "\n",
    "print(os.getenv('work',-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分组卷积工作原理\n",
    "Group convolution（分组卷积）的工作原理涉及将输入和输出通道分成若干组，以便对每组进行独立的卷积操作。以下是分组卷积的基本工作原理：\n",
    "\n",
    "1. **通道分组：** 首先，输入通道和输出通道被划分为 \\(G\\) 组，其中 \\(G\\) 是分组数。每个组内有相等数量的输入通道和输出通道。例如，如果输入通道数是 \\(C_{\\text{in}}\\)，输出通道数是 \\(C_{\\text{out}}\\)，而分组数是 \\(G\\)，则每个分组内的通道数量为 \\(C_{\\text{in}}/G\\) 和 \\(C_{\\text{out}}/G\\)。\n",
    "\n",
    "2. **独立卷积操作：** 对于每个分组，分别使用相应的输入通道组和输出通道组执行卷积操作。每组都有自己的卷积核集合，这些卷积核仅与相应的输入通道组相关联。这意味着每个分组都有自己独立的卷积过程，独立生成输出通道组。\n",
    "\n",
    "3. **结果拼接：** 将每个分组产生的输出通道组合并成最终的输出。这个过程涉及将每个分组的输出通道按照通道维度进行拼接，形成最终的输出特征图。\n",
    "\n",
    "这种方式使得每个分组内的通道只与同组内的通道进行卷积操作，而不与其他分组的通道进行卷积。这可以在一定程度上减少模型的参数量，并且提高计算效率。\n",
    "\n",
    "下面是一个简单的伪代码表示，说明了分组卷积的基本工作原理：\n",
    "\n",
    "```python\n",
    "# 伪代码示例\n",
    "for each_group in range(groups):\n",
    "    # 从输入通道和输出通道中选择相应的通道组\n",
    "    input_channel_group = input_channels[each_group * (C_in // groups) : (each_group + 1) * (C_in // groups)]\n",
    "    output_channel_group = output_channels[each_group * (C_out // groups) : (each_group + 1) * (C_out // groups)]\n",
    "\n",
    "    # 使用相应的通道组进行独立的卷积操作\n",
    "    output_group = convolve(input_channel_group, output_channel_group, kernel_size, stride, padding)\n",
    "\n",
    "    # 存储每个分组的输出\n",
    "\n",
    "# 将每个分组的输出拼接成最终的输出特征图\n",
    "final_output = concatenate(output_group_1, output_group_2, ..., output_group_G)\n",
    "```\n",
    "\n",
    "这就是分组卷积的基本工作原理，通过对通道进行分组，实现了部分独立卷积，从而减少了参数量。\n",
    "\n",
    "分组卷积（Group Convolution）是通过将输入和输出通道划分为若干组，每组内的通道独立进行卷积操作来实现的。这样，卷积核也被分成了若干组，每组与相应的输入通道组相连，从而完成卷积运算。下面是分组卷积的公式和方法的简要描述：\n",
    "\n",
    "### 公式：\n",
    "\n",
    "对于输入特征图 \\(X\\) 和输出特征图 \\(Y\\)，以及分组卷积的参数（卷积核权重） \\(W\\)，分组卷积的输出可以表示为：\n",
    "\n",
    "$$\n",
    "Y_{i,j,k} = \\sum_{l=0}^{C_{\\text{in}}/G - 1} \\sum_{m=0}^{H_{\\text{f}} - 1} \\sum_{n=0}^{W_{\\text{f}} - 1} X_{i,l \\cdot G + m,j \\cdot S + n} \\cdot W_{k,l,m,n}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- \\(Y_{i,j,k}\\) 是输出特征图的第 \\(i\\) 个样本的第 \\(j\\) 个通道的第 \\(k\\) 个元素。\n",
    "- \\(X_{i,c,h,w}\\) 是输入特征图的第 \\(i\\) 个样本的第 \\(c\\) 个通道的第 \\(h\\) 行、第 \\(w\\) 列的元素。\n",
    "- \\(W_{k,c,m,n}\\) 是第 \\(k\\) 个输出通道的第 \\(c\\) 个输入通道的卷积核的第 \\(m\\) 行、第 \\(n\\) 列的权重。\n",
    "- \\(C_{\\text{in}}\\) 是输入通道数，\\(H_{\\text{f}}\\) 和 \\(W_{\\text{f}}\\) 是卷积核的高度和宽度，\\(S\\) 是卷积的步幅，\\(G\\) 是分组数。\n",
    "\n",
    "### 方法：\n",
    "\n",
    "1. **分组划分：** 将输入和输出通道分成 \\(G\\) 组，确保输入通道数和输出通道数都是 \\(G\\) 的整数倍。\n",
    "\n",
    "2. **分组卷积操作：** 对于每个分组，独立地对输入通道和输出通道进行卷积操作。这就意味着每个分组有自己的卷积核集合，用于处理相应的输入通道和生成相应的输出通道。\n",
    "\n",
    "3. **拼接结果：** 将各个分组的卷积结果进行拼接，得到最终的输出特征图。\n",
    "\n",
    "在PyTorch中，通过设置`groups`参数来实现分组卷积。例如，`nn.Conv2d(in_channels=..., out_channels=..., kernel_size=..., groups=...)`中的`groups`参数即用于指定分组卷积的分组数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显卡是否可用True\n",
      "显卡信息：NVIDIA GeForce MX150\n",
      "显存大小: 2147352576\n",
      "核心频率: _CudaDeviceProperties(name='NVIDIA GeForce MX150', major=6, minor=1, total_memory=2047MB, multi_processor_count=3)\n",
      "Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"显卡是否可用{torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"显卡信息：{torch.cuda.get_device_name()}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    memory_size = torch.cuda.get_device_properties(device).total_memory\n",
    "    print(\"显存大小:\", memory_size)\n",
    "    frequency = torch.cuda.get_device_properties(device)#.clock_rate\n",
    "    print(\"核心频率:\", frequency)\n",
    "# 普通卷积\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "print(conv1)\n",
    "\n",
    "# 分组卷积，每个输入通道独立卷积，输出通道数也是输入通道数\n",
    "conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1, groups=3)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ord()表示给定字符的 Unicode 码点（code point）\n",
    "\n",
    "在 Python 中，ord() 函数是一个内置函数，用于返回表示给定字符的 Unicode 码点（code point）。它接受一个字符串参数，该字符串应该是长度为 1 的字符。然后，它返回一个表示该字符 Unicode 码点的整数值。\n",
    "```python\n",
    "ord(character)\n",
    "```\n",
    "其中，`character`是是要获取 Unicode 码点的字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20320\n",
      "97\n",
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ord(\"你\"))\n",
    "print(ord(\"a\"))\n",
    "print(ord(\"A\"))\n",
    "list(range(ord(\"!\"), ord(\"~\")+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello']\n",
      "['h', 'e', 'l', 'l', 'o', ' ', ',', ' ', 'w', 'o', 'r', 'd', '!']\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\".split())\n",
    "print(list(\"hello , word!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python中set数据结构和dict数据结构的区别与联系\n",
    "\n",
    "在 Python 中，`set` 和 `dict` 都是常用的数据结构，它们有一些相似之处，但也有一些重要的区别。\n",
    "\n",
    "1. **相同点**：\n",
    "\n",
    "   - **无序性**：`set` 和 `dict` 中的元素都是无序的，即它们的元素没有固定的顺序。\n",
    "   \n",
    "   - **唯一性**：`set` 中的元素是唯一的，而 `dict` 中的键是唯一的。\n",
    "\n",
    "2. **区别**：\n",
    "\n",
    "   - **存储内容**：\n",
    "     \n",
    "     - `set` 是由一组唯一的元素组成的无序集合。\n",
    "     \n",
    "     - `dict` 是由一组键值对（key-value pairs）组成的，其中每个键都是唯一的，而值可以重复。\n",
    "\n",
    "   - **元素访问**：\n",
    "     \n",
    "     - 在 `set` 中，元素是通过成员关系测试（membership tests）来访问的，即通过检查元素是否属于集合来确定。\n",
    "     \n",
    "     - 在 `dict` 中，元素是通过键来访问的，即通过键来获取对应的值。\n",
    "\n",
    "3. **联系**：\n",
    "\n",
    "   - `set` 和 `dict` 都可以通过大括号 `{}` 来创建。\n",
    "   \n",
    "   - `set` 和 `dict` 都可以使用迭代器（iterators）来遍历其中的元素。\n",
    "   \n",
    "   - `set` 和 `dict` 都是可变的数据结构，可以动态地添加、删除元素。\n",
    "   \n",
    "   - `set` 和 `dict` 都可以进行集合运算，如并集、交集、差集等。\n",
    "4. 使用场景\n",
    "`set` 和 `dict` 都是 Python 中常用的数据结构，它们都有自己独特的特点和用途。\n",
    "   - `set` 用于存储一组唯一的元素，适合于需要快速查找、去重的场景；\n",
    "   - `dict` 用于存储键值对的映射关系，适合于需要按照键来检索值的场景。\n",
    "\n",
    "```python\n",
    "# 创建一个集合\n",
    "my_set = {1, 2, 3, 4, 5}\n",
    "\n",
    "# 创建一个字典\n",
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "# 访问集合中的元素\n",
    "for element in my_set:\n",
    "    print(element)\n",
    "\n",
    "# 访问字典中的键值对\n",
    "for key, value in my_dict.items():\n",
    "    print(key, value)\n",
    "\n",
    "# 添加元素到集合\n",
    "my_set.add(6)\n",
    "\n",
    "# 添加键值对到字典\n",
    "my_dict['d'] = 4\n",
    "\n",
    "print(my_set)  # 输出：{1, 2, 3, 4, 5, 6}\n",
    "print(my_dict)  # 输出：{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ftfy修复 Unicode 文本的编码问题\n",
    "`ftfy` 是 Python 中的一个库，全称为 \"fixes text for you\"。它用于修复 Unicode 文本的编码问题，使得文本能够正确地解码和显示。\n",
    "\n",
    "以下是一个简单的代码示例，演示了如何使用 `ftfy` 库修复文本编码问题：\n",
    "\n",
    "```python\n",
    "import ftfy\n",
    "\n",
    "# 一个包含编码问题的文本\n",
    "text_with_encoding_issue = 'This is a test \\ud83d\\ude00'  # 包含了一个无效的 Unicode 字符\n",
    "\n",
    "# 使用 ftfy 修复编码问题\n",
    "fixed_text = ftfy.fix_text(text_with_encoding_issue)\n",
    "\n",
    "print(fixed_text)  # 输出：\"This is a test 😀\"\n",
    "```\n",
    "\n",
    "在这个示例中，原始文本包含一个无效的 Unicode 字符 `\\ud83d\\ude00`（这是笑脸表情符号），在某些情况下可能导致解码错误。通过调用 `ftfy.fix_text()` 函数，`ftfy` 库会自动检测并修复这个编码问题，最终将文本正确地解码为 \"This is a test 😀\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test 😀\n"
     ]
    }
   ],
   "source": [
    "import ftfy\n",
    "\n",
    "# 一个包含编码问题的文本\n",
    "text_with_encoding_issue = 'This is a test \\ud83d\\ude00'  # 包含了一个无效的 Unicode 字符\n",
    "\n",
    "# 使用 ftfy 修复编码问题\n",
    "fixed_text = ftfy.fix_text(text_with_encoding_issue)\n",
    "\n",
    "print(fixed_text)  # 输出：\"This is a test 😀\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 防止出现路径错误问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m FILE \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m      5\u001b[0m ROOT \u001b[38;5;241m=\u001b[39m FILE\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# YOLOv5 root directory\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ROOT) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# platform 判断平台"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "MACOS, LINUX, WINDOWS = (platform.system() == x for x in ['Darwin', 'Linux', 'Windows'])  # environment booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 路径处理\n",
    "## pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_qwertyuiop0\n",
      "/root/home/user1/test_qwertyuiop0_openvino_model/\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "file_path='/root/home/user1/test_qwertyuiop0.png'\n",
    "f=Path(file_path)\n",
    "f1 = str(f).replace(f.suffix, f'_openvino_model{os.sep}')\n",
    "print(f.stem)\n",
    "print(f1)\n",
    "print(isinstance(file_path,str))\n",
    "print('.png' in file_path)\n",
    "print('.png1' in file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串处理\n",
    "## replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.state.module.layer1\n",
      "net.stata1.m.layer1\n"
     ]
    }
   ],
   "source": [
    "s1=\"net.state.module.layer1\"\n",
    "s2=\"net.stata1.m.layer1\"\n",
    "\n",
    "s1_o=s1.replace(\"moudle.\",\"\")\n",
    "s2_o=s2.replace(\"module.\",\"\")\n",
    "print(s1_o)\n",
    "print(s2_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256, 512, 1024, 2048]\n",
      "<generator object <genexpr> at 0x7f43eb3229d0>\n",
      "(1, 1, 1)\n",
      "/model_name/UNet_Fold0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# list\n",
    "root_featmap_nums = 64\n",
    "featmaps = [root_featmap_nums*2**i for i in range(6)]\n",
    "print(featmaps)\n",
    "# tuple\n",
    "print((1 for i in range(2)))\n",
    "print(tuple([1 for i in range(3)]))\n",
    "# path\n",
    "save_ckpt = os.path.join(\"/\", \"model_name\", \"{}_Fold{}\".format(\"UNet\", 0))\n",
    "print(save_ckpt)\n",
    "# if\n",
    "internal_channels=8\n",
    "internal_channels= 1 if internal_channels==0 else internal_channels\n",
    "print(internal_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.cat\n",
    "a=[]\n",
    "for i in range(4):\n",
    "    a.append(torch.ones(1,4,4))\n",
    "a_=torch.cat(a,dim=0)\n",
    "print(a_.shape)\n",
    "print(a_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 装饰器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is happening before the function is called.\n",
      "Hello!\n",
      "Something is happening after the function is called.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 02:47:53,134 - INFO - Executing add_numbers with arguments (3, 5) and keyword arguments {}.\n",
      "2024-01-05 02:47:53,135 - INFO - add_numbers executed successfully. Result: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function executed.\n",
      "example_function took 2.0009446144104004 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\"Something is happening before the function is called.\")\n",
    "        func()\n",
    "        print(\"Something is happening after the function is called.\")\n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def say_hello():\n",
    "    print(\"Hello!\")\n",
    "\n",
    "say_hello()\n",
    "import time\n",
    "\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} took {end_time - start_time} seconds to run.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def example_function():\n",
    "    # Some time-consuming task\n",
    "    time.sleep(2)\n",
    "    print(\"Function executed.\")\n",
    "\n",
    "example_function()\n",
    "\n",
    "import logging\n",
    "from functools import wraps\n",
    "\n",
    "def logging_decorator(func):\n",
    "    \"\"\"\n",
    "    Decorator that logs information about the function's execution.\n",
    "    \n",
    "    Parameters:\n",
    "    - func: The function to be decorated.\n",
    "    \n",
    "    Returns:\n",
    "    The decorated function.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(f\"Executing {func.__name__} with arguments {args} and keyword arguments {kwargs}.\")\n",
    "        result = func(*args, **kwargs)\n",
    "        logging.info(f\"{func.__name__} executed successfully. Result: {result}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# 配置日志记录\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 使用装饰器\n",
    "@logging_decorator\n",
    "def add_numbers(a, b):\n",
    "    \"\"\"\n",
    "    Example function that adds two numbers.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 调用被装饰的函数\n",
    "result = add_numbers(3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “*”作为函数参数的作用\n",
    "## 收集任意数量的位置参数 `*args`\n",
    "如果你想要一个函数能够接受任意数量的位置参数，你可以使用一个带有星号的参数，但是这个星号后面必须有一个参数名。\n",
    "\n",
    "这里的`*args`表示收集任意数量的位置参数，并将它们存储在元组 `args` 中。这样，你可以在函数体内循环访问这些参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> (1, 2, 3, 5, 5, 6, 3)\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def star_args_usage(*args):\n",
    "    print(type(args),args)\n",
    "    for i in args:\n",
    "        print(i)\n",
    "star_args_usage(1,2,3,5,5,6,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定关键字参数 \n",
    "测试函数中单独一个“*”的作用：\n",
    "如果你想在函数定义中指定一些必须使用关键字传递的参数，可以使用带有星号的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n",
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "def star_usage(*,a,b,c=3):\n",
    "    \"\"\"_summary_\n",
    "    测试函数中单独一个“*”的作用：\n",
    "    在你提供的函数签名中，*（单独的星号）的作用是指定在此之后的参数必须使用关键字传递，而不能使用位置传递。这样的语法用于强制调用者在调用函数时通过关键字明确指定某些参数的值。\n",
    "    Args:\n",
    "        a (int, optional): _description_. Defaults to 1.\n",
    "        b (int, optional): _description_. Defaults to 2.\n",
    "        c (int, optional): _description_. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return a,b,c\n",
    "def star_usage1(a,b,*,c,d):\n",
    "    \"\"\"\n",
    "    在这个例子中,a 和 b 是位置参数，而 c 和 d 必须使用关键字传递。这是因为在星号后的参数只能通过关键字传递。\n",
    "    \"\"\"\n",
    "    return a,b,c,d\n",
    "print(star_usage(a=2,b=3,c=4))\n",
    "print(star_usage1(1,2,c=2,d=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解包可迭代对象\n",
    "如果在函数调用时使用星号（*），则表示将一个可迭代对象（如列表或元组）解包为单独的位置参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "def example_function(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "my_list = [1, 2, 3]\n",
    "\n",
    "example_function(*my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **kwags\n",
    "在Python中，`**kwargs` 是一种用于函数定义的语法，表示函数可以接受任意数量的关键字参数，并将这些参数收集到一个字典中。\"kwargs\" 通常是 \"keyword arguments\" 的缩写。\n",
    "1. 接受任意数量的关键字参数： `**kwargs` 允许函数接受不定数量的关键字参数。这样，函数的调用者可以传递任意数量的关键字参数，而函数将它们作为一个字典进行处理。\n",
    "2. 与其他参数一起使用： `**kwargs` 可以与其他参数一起使用，但通常放在参数列表的末尾。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> {'a': 1, 'b': 2}\n",
      "a\n",
      "b\n",
      "<class 'dict'> {'a': 1, 'b': 3, 'c': 2}\n",
      "a\n",
      "b\n",
      "c\n",
      "<class 'dict'> {'a': 1, 'b': 2}\n",
      "a\n",
      "b\n",
      "<class 'dict'> {'a': 1, 'b': 3, 'c': 2}\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "def sstar_args_usage(**kwargs):\n",
    "    print(type(kwargs),kwargs)\n",
    "    for i in kwargs:\n",
    "        print(i)\n",
    "\n",
    "def sstar_args_usage1(x,y,**kwargs):\n",
    "    print(type(kwargs),kwargs)\n",
    "    for i in kwargs:\n",
    "        print(i)\n",
    "        \n",
    "sstar_args_usage(a=1,b=2)\n",
    "kwargs={'a':1,'b':3,'c':2}\n",
    "sstar_args_usage(**kwargs)\n",
    "\n",
    "sstar_args_usage1(-1,0,a=1,b=2)\n",
    "sstar_args_usage1(-1,0,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `**variable`解包字典可迭代对象 \n",
    "\n",
    "在Python中，**variable（variable可以是任意合法的变量名）作为函数的参数传递时，它的作用是将字典中的键值对解包为关键字参数，其中字典是由变量 variable 所引用的。\n",
    "\n",
    "具体来说，如果一个函数的定义中使用了 **variable，那么在调用该函数时，可以将一个字典传递给这个变量，而字典中的键值对将会被解包为关键字参数。这种方式使得在函数调用时能够动态地传递参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name John\n",
      "age 25\n",
      "city New York\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "def example_function(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(key, value)\n",
    "\n",
    "def exp2(a,b,c):\n",
    "    print(a,b,c)\n",
    "# 定义一个字典\n",
    "my_dict = {'name': 'John', 'age': 25, 'city': 'New York'}\n",
    "\n",
    "# 将字典解包为关键字参数\n",
    "example_function(**my_dict)\n",
    "vari={'a':1,'b':2,'c':3}\n",
    "exp2(**vari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，example_function 接受字典中的键值对作为关键字参数，并将它们打印出来。使用 **my_dict 的语法将字典解包，使得函数能够动态处理字典中的内容。\n",
    "\n",
    "需要注意的是，传递的字典中的键必须与函数定义中的参数名相匹配，否则会引发 TypeError。这种方式常用于编写通用函数，特别是在处理配置参数、动态生成函数参数等场景下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thop 库\n",
    "`thop`（Torch Operation Counter）是一个用于统计PyTorch模型中浮点运算数（FLOPs）和参数数量的库。FLOPs是模型进行推理时执行的浮点运算的数量，通常用于衡量模型的计算复杂度。参数数量是模型中需要学习的权重和偏置的数量。\n",
    "\n",
    "`thop` 提供了一个轻量级的工具，可以在不执行实际的前向传播的情况下，仅通过分析模型的计算图（图的结构）来估计模型的计算复杂度。这对于模型设计和优化非常有用，因为可以在模型构建之前就大致了解模型的计算和内存需求。\n",
    "\n",
    "以下是使用 `thop` 库的基本步骤：\n",
    "\n",
    "1. 安装 `thop` 库：`pip install thop`\n",
    "\n",
    "2. 导入库：`from thop import profile`\n",
    "\n",
    "3. 定义一个输入张量，通常是模型的输入大小。\n",
    "\n",
    "4. 使用 `profile` 函数来获取模型的计算复杂度和参数数量。\n",
    "\n",
    "以下是一个简单的示例：\n",
    "在这个例子中，`profile` 函数分析了 `SimpleModel` 的计算图，估计了前向传播时的FLOPs和参数数量，并将其打印出来。这对于理解模型的计算复杂度和优化模型非常有帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "torch.Size([1, 64, 30, 30])\n",
      "torch.Size([1, 57600])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x57600 and 64x900)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 使用 thop 的 profile 函数\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m flops, params \u001b[38;5;241m=\u001b[39m \u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOPs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflops\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/thop/profile.py:212\u001b[0m, in \u001b[0;36mprofile\u001b[0;34m(model, inputs, custom_ops, verbose, ret_layer_info, report_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(add_hooks)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs_count\u001b[39m(module: nn\u001b[38;5;241m.\u001b[39mModule, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    215\u001b[0m     total_ops, total_params \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mtotal_ops\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m, in \u001b[0;36mSimpleModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x57600 and 64x900)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        print(x.shape)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        # x = self.fc(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "\n",
    "# 定义输入大小\n",
    "input_tensor = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# 使用 thop 的 profile 函数\n",
    "flops, params = profile(model, inputs=(input_tensor,))\n",
    "\n",
    "print(f\"FLOPs: {flops}\")\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
